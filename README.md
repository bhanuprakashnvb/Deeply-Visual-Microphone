# Deeply-Visual-Microphone

Roughly a decade ago, there was a breakthrough in the
field of computer vision where a team at MIT demonstrated
a research wherein they utilized high-speed video footage
of sound interacting with an objectâ€™s surface and captured
minuscule vibrations to partially reconstruct the original
sound waves. We are pioneering a novel approach aimed
at determining whether replacing the traditional mathemat-
ical methods used in the primary study with deep learn-
ing techniques would enhance sound extraction. We use a
pseudo-Siamese network with pre-trained ResNet50 model
and a custom CNN architecture on the original data set
augmented with our own data set to demonstrate a proof
of concept. We further delve into feature pyramid networks
to enhance the reasoning capability of the model.
